@inproceedings{roijers2021following,
  author       = "Roijers, {Diederik M.} and Willem R{\"o}pke and Ann Nowe and Roxana Radulescu",
  title        = "On Following Pareto-Optimal Policies in Multi-Objective Planning and Reinforcement Learning",
  booktitle    = "Proceedings of the Multi-Objective Decision Making Workshop 2021 (MODeM-21)",
  year         = "2021",
  month        = "7",
}

@inproceedings{ropke2021communication,
  author       = "Willem R{\"o}pke and Roxana Radulescu and Roijers, {Diederik M.} and Ann Nowe",
  title        = "Communication Strategies in Multi-Objective Normal-Form Games",
  booktitle    = "Proceedings of the Adaptive and Learning Agents Workshop 2021 (ALA-21)",
  year         = "2021",
  month        = "5",
}

@inproceedings{ropke2021nashworkshop,
  author       = "Willem R{\"o}pke and Roijers, {Diederik M.} and Ann Nowe and Roxana Radulescu",
  title        = "On Nash Equilibria for Multi-Objective Normal Form Games under Scalarised Expected Returns versus Expected Scalarised Returns",
  booktitle    = "Proceedings of the Multi-Objective Decision Making Workshop 2021 (MODeM-21)",
  year         = "2021",
  month        = "7",
}

@mastersthesis{ropke2021thesis,
  author  = "Willem R{\"o}pke",
  title   = "Communication In Multi-Objective Games",
  school  = "Vrije Universiteit Brussel",
  year    = "2021",
  type    = "Master thesis",
  address = "Brussels",
  month   = "June",
}

@inproceedings{ropke2022commitment,
  title = {Commitment and {{Cyclic Strategies}} in {{Multi-Objective Games}}},
  booktitle = {Proceedings of the {{Adaptive}} and {{Learning Agents Workshop}} ({{ALA}} 2022)},
  author = {R{\"o}pke, Willem and Radulescu, Roxana and Now{\'e}, Ann and Roijers, Diederik M.},
  editor = {Cruz, Francisco and Hayes, Conor F. and {da Silva}, Felipe Leno and Santos, Fernando P.},
  year = {2022},
  month = may,
  pages = {9},
  address = {{Online, \url{https://ala2022.github.io/}}}
}


@inproceedings{ropke2019dustt,
  title = {{{DuStt}} \textendash{} a {{Speech-to-Text Engine}} for {{Dutch}}: {{Demo Abstract}}},
  booktitle = {Proceedings of the 31st {{Benelux Conference}} on {{Artificial Intelligence}} ({{BNAIC}} 2019)},
  author = {R{\"o}pke, Willem and Radulescu, Roxana and Efthymiadis, Kyriakos and Now{\'e}, Ann},
  editor = {Beuls, Katrien and Bogaerts, Bart and Bontempi, Gianluca and Geurts, Pierre and Harley, Nick and Lebichot, Bertrand and Lenaerts, Tom and Louppe, Gilles and Van Eecke, Paul},
  year = {2019},
  volume = {2491},
  publisher = {{CEUR Workshop Proceedings}},
  abstract = {We develop and demonstrate a speech-to-text engine for Dutch, starting from the open-source project DeepSpeech and using the Corpus Gesproken Nederlands. The DuStt engine provides models targeted towards Dutch, Flemish or speakers from both Belgium and The Netherlands. Users can upload or record their own input as well as load pre-recorded samples and obtain a transcription on the spot. The demonstration is video available at: https://youtu.be/DtTK0uo5W7s.}
}

@inproceedings{ropke2019training,
  title = {Training a {{Speech-to-Text Model}} for {{Dutch}} on the {{Corpus Gesproken Nederlands}}},
  booktitle = {Proceedings of the 31st {{Benelux Conference}} on {{Artificial Intelligence}} ({{BNAIC}} 2019)},
  author = {R{\"o}pke, Willem and Radulescu, Roxana and Efthymiadis, Kyriakos and Now{\'e}, Ann},
  editor = {Beuls, Katrien and Bogaerts, Bart and Bontempi, Gianluca and Geurts, Pierre and Harley, Nick and Lebichot, Bertrand and Lenaerts, Tom and Louppe, Gilles and Van Eecke, Paul},
  year = {2019},
  volume = {2491},
  publisher = {{CEUR Workshop Proceedings}},
  abstract = {Speech-to-text, also known as Speech Recognition, is a technology that is able to recognize and transcribe spoken language into text. In subsequent steps, this transcription can be used to complete a multitude of tasks, such as providing automatic subtitles or parsing voice commands. In recent years, Speech-to-Text models have dramatically improved thanks partially to advances in Deep Learning methods. Starting from the open-source project DeepSpeech, we train speech-to-text models for Dutch, using the Corpus Gesproken Nederlands (CGN). First, we contribute a pre-processing pipeline for this dataset, to make it suitable for the task at hand, obtaining a ready-to-use speech-to-text dataset for Dutch. Second, we investigate the performance of Dutch and Flemish models trained from scratch, establishing a baseline for the CGN dataset for this task. Finally, we investigate the issue of transferring speech-to-text models between related languages. In this case, we analyse how a pre-trained English model can be transferred and fine-tuned for Dutch.}
}

@article{ropke2022preference,
  title = {Preference Communication in Multi-Objective Normal-Form Games},
  author = {R{\"o}pke, Willem and Roijers, Diederik M. and Now{\'e}, Ann and R{\u a}dulescu, Roxana},
  year = {2022},
  month = jul,
  journal = {Neural Computing and Applications},
  issn = {0941-0643, 1433-3058},
  doi = {10.1007/s00521-022-07533-6},
  abstract = {We consider preference communication in two-player multi-objective normal-form games. In such games, the payoffs resulting from joint actions are vector-valued. Taking a utility-based approach, we assume there exists a utility function for each player which maps vectors to scalar utilities and consider agents that aim to maximise the utility of expected payoff vectors. As agents typically do not know their opponent's utility function or strategy, they must learn policies to interact with each other. Inspired by Stackelberg games, we introduce four novel preference communication protocols to aid agents in arriving at adequate solutions. Each protocol describes a specific approach for one agent to communicate preferences over their actions and how another agent responds. Additionally, to study when communication emerges, we introduce a communication protocol where agents must learn when to communicate. These protocols are subsequently evaluated on a set of five benchmark games against baseline agents that do not communicate. We find that preference communication can alter the learning process and lead to the emergence of cyclic policies which had not been previously observed in this setting. We further observe that the resulting policies can heavily depend on the characteristics of the game that is played. Lastly, we find that communication naturally emerges in both cooperative and self-interested settings.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/willemropke/Zotero/storage/YG4GLP9H/Röpke et al. - 2022 - Preference communication in multi-objective normal.pdf}
}

@article{ropke2022nash,
  title = {On Nash Equilibria in Normal-Form Games with Vectorial Payoffs},
  author = {R{\"o}pke, Willem and Roijers, Diederik M. and Now{\'e}, Ann and R{\u a}dulescu, Roxana},
  year = {2022},
  month = oct,
  journal = {Autonomous Agents and Multi-Agent Systems},
  volume = {36},
  number = {2},
  pages = {53},
  issn = {1573-7454},
  doi = {10.1007/s10458-022-09582-6},
  abstract = {We provide an in-depth study of Nash equilibria in multi-objective normal-form games (MONFGs), i.e., normal-form games with vectorial payoffs. Taking a utility-based approach, we assume that each player's utility can be modelled with a utility function that maps a vector to a scalar utility. In the case of a mixed strategy, it is meaningful to apply such a scalarisation both before calculating the expectation of the payoff vector as well as after. This distinction leads to two optimisation criteria. With the first criterion, players aim to optimise the expected value of their utility function applied to the payoff vectors obtained in the game. With the second criterion, players aim to optimise the utility of expected payoff vectors given a joint strategy. Under this latter criterion, it was shown that Nash equilibria need not exist. Our first contribution is to provide a sufficient condition under which Nash equilibria are guaranteed to exist. Secondly, we show that when Nash equilibria do exist under both criteria, no equilibrium needs to be shared between the two criteria, and even the number of equilibria can differ. Thirdly, we contribute a study of pure strategy Nash equilibria under both criteria. We show that when assuming quasiconvex utility functions for players, the sets of pure strategy Nash equilibria under both optimisation criteria are equivalent. This result is further extended to games in which players adhere to different optimisation criteria. Finally, given these theoretical results, we construct an algorithm to compute all pure strategy Nash equilibria in MONFGs where players have a quasiconvex utility function.},
  copyright = {All rights reserved},
  file = {/Users/willemropke/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/Papers/On nash equilibria in normal-form games with vectorial payoffs.pdf}
}

@inproceedings{ropke2022multi,
  title={Multi-Objective Scheduling for Agricultural Interventions},
  author={\textbf{R{\"o}pke}, \textbf{Willem} and Pollaci, Samuele and Vandenbogaerde, Bram and Li, Jiahong and Coppens, Youri},
  booktitle={BNAIC/BENELEARN},
  year={2022}
}

@inproceedings{ropke2022communication,
  title={Communication In Multi-Objective Games},
  author={\textbf{Röpke}, \textbf{Willem} and Roijers, Diederik M. and R\u{a}dulescu, Roxana and Nowé, Ann},
  booktitle={BNAIC/BENELEARN},
  year={2022}
}

@misc{ropke2023bridging,
  doi = {10.48550/ARXIV.2301.05755},
  
  url = {https://arxiv.org/abs/2301.05755},
  
  author = {\textbf{Röpke}, \textbf{Willem} and Groenland, Carla and Rădulescu, Roxana and Nowé, Ann and Roijers, Diederik M.},
  
  keywords = {Computer Science and Game Theory (cs.GT), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Bridging the Gap Between Single and Multi Objective Games},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}